# preprocess.py (æ–°ç‰ˆï¼šå¤„ç†åŒ»ç–—JSONæ•°æ®)
import os
import json
from tqdm import tqdm

# è¾“å…¥æ–‡ä»¶ï¼šä½ ä¿å­˜çš„æ–°æ•°æ®é›†
INPUT_FILE = os.path.join("data", "medical_data.json")
# è¾“å‡ºæ–‡ä»¶ï¼šæ„å»ºå‘é‡åº“æ‰€éœ€çš„ä¸­é—´æ ¼å¼
OUTPUT_FILE = os.path.join("data", "processed_data.json")


def process_data():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° {INPUT_FILE}ï¼Œè¯·å…ˆå°†æ•°æ®é›†ä¿å­˜ä¸ºè¯¥æ–‡ä»¶ã€‚")
        return

    print(f"ğŸ“¥ æ­£åœ¨è¯»å– {INPUT_FILE} ...")
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)

    processed_data = []

    print(f"ğŸ§¹ å¼€å§‹å¤„ç† {len(raw_data)} æ¡æ•°æ®...")

    for item in tqdm(raw_data):
        # 1. æå–å­—æ®µ
        # ä½¿ç”¨ 'question' ä½œä¸ºæ ‡é¢˜ï¼Œè¿™æ ·æ£€ç´¢æ—¶åŒ¹é…åº¦æ›´é«˜
        title = item.get('question', 'æœªçŸ¥é—®é¢˜')

        # 2. æ„é€ ç”¨äºæ£€ç´¢å’Œå›ç­”çš„å†…å®¹å— (Content)
        # å°†é—®é¢˜ã€ç­”æ¡ˆå’Œè¯æ®ç»„åˆåœ¨ä¸€èµ·ï¼Œæä¾›å®Œæ•´çš„ä¸Šä¸‹æ–‡ç»™ LLM
        answer = item.get('answer', '')
        evidence = item.get('evidence', '')

        # ç»„åˆæˆä¸€ä¸ªæ¸…æ™°çš„æ–‡æœ¬å—
        content = f"é—®é¢˜ï¼š{title}\nç­”æ¡ˆï¼š{answer}\nåŒ»å­¦è¯æ®ï¼š{evidence}"

        # 3. æ„é€  build_db.py éœ€è¦çš„å­—å…¸æ ¼å¼
        processed_data.append({
            "source": item.get('source', 'Medical DB'),  # æ¥æº
            "id": item.get('id', ''),
            "title": title,  # æ ‡é¢˜ï¼ˆç”¨äºå±•ç¤ºå¼•ç”¨ï¼‰
            "publish_time": "2025",  # æ•°æ®é›†æœªæä¾›æ—¶é—´ï¼Œç»™ä¸ªé»˜è®¤å€¼
            "content": content  # æ ¸å¿ƒæ–‡æœ¬ï¼ˆç”¨äºå‘é‡åŒ–ï¼‰
        })

    # ä¿å­˜å¤„ç†åçš„æ•°æ®
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(processed_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼å…± {len(processed_data)} æ¡ã€‚")
    print(f"ğŸ“ å·²ä¿å­˜è‡³ {OUTPUT_FILE}")
    print("ğŸ‘‰ ä¸‹ä¸€æ­¥ï¼šè¿è¡Œ build_db.py æ„å»ºå‘é‡åº“")


if __name__ == "__main__":
    process_data()