# build_db.py
import json
import os
import pickle
from tqdm import tqdm
from sentence_transformers import SentenceTransformer

DATA_PATH = os.path.join("data", "processed_data.json")
DB_PATH = "vector_db.pkl"
# å‘é‡æ¨¡å‹ (Bi-Encoder)
MODEL_NAME = "BAAI/bge-small-zh-v1.5"


def build_database():
    if not os.path.exists(DATA_PATH):
        print("âŒ é”™è¯¯ï¼šè¯·å…ˆè¿è¡Œ preprocess.py")
        return

    with open(DATA_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹ {MODEL_NAME} ...")
    # normalize_embeddings=True å¯¹ä½™å¼¦ç›¸ä¼¼åº¦æ£€ç´¢å¾ˆé‡è¦
    model = SentenceTransformer(MODEL_NAME)

    db_data = []
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå‘é‡ (å…± {len(data)} æ¡åˆ‡ç‰‡)...")

    # æ‰¹é‡å¤„ç†å¯ä»¥ç¨å¾®å¿«ä¸€ç‚¹ï¼Œä½†ä¸ºäº†è¿›åº¦æ¡æ˜¾ç¤ºï¼Œæˆ‘ä»¬è¿™é‡Œè¿˜æ˜¯é€æ¡æˆ–å°æ‰¹é‡
    # æ„é€  "Instruct: ... Query: ..." æ ¼å¼å¯¹äº BGE æ¨¡å‹æœ‰åŠ æˆï¼Œä½†è¿™é‡Œæ˜¯å­˜åº“ï¼Œç›´æ¥å­˜å†…å®¹å³å¯
    # ä¹Ÿå¯ä»¥å°†æ ‡é¢˜åŠ å…¥å‘é‡è®¡ç®—å¢åŠ è¯­ä¹‰

    texts_to_encode = [f"{item['title']}ï¼š{item['content']}" for item in data]

    # æ‰¹é‡ç¼–ç 
    embeddings = model.encode(texts_to_encode, normalize_embeddings=True, show_progress_bar=True)

    for i, item in enumerate(data):
        db_data.append({
            "vector": embeddings[i],  # numpy array
            "content": item['content'],
            "title": item['title'],
            "source": item['source'],
            "publish_time": item.get('publish_time', '')
        })

    with open(DB_PATH, 'wb') as f:
        pickle.dump(db_data, f)
    print(f"âœ… æ•°æ®åº“æ„å»ºå®Œæˆï¼å·²ä¿å­˜è‡³ {DB_PATH}")


if __name__ == "__main__":
    build_database()